{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc5d004-5e6f-4bb3-938e-fb44f919cec3",
   "metadata": {},
   "source": [
    "# `nanoGPT`: GPT-2 Small (125M Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd994b32-ca5f-4e00-81d3-89dbbf7b2093",
   "metadata": {},
   "source": [
    "## Install / Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c38d27-5acb-4e5d-87c8-dbb2739cf277",
   "metadata": {},
   "source": [
    "### First Time Running\n",
    "\n",
    "We need to install `ngpt` and setup the Shakespeare dataset\n",
    "\n",
    "This will need to be ran the first time you are running this notebook.\n",
    "\n",
    "Following the\n",
    "\n",
    "```python\n",
    "!python3 -m pip install nanoGPT\n",
    "```\n",
    "\n",
    "you will need to restart your runtime (Runtime -> Restart runtime)\n",
    "\n",
    "After this, you should be able to\n",
    "\n",
    "```python\n",
    ">>> import ngpt\n",
    ">>> ngpt.__file__\n",
    "'/content/nanoGPT/src/ngpt/__init__.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed59c1f-e6c9-4222-bded-5a32e4505ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:22:55.857425Z",
     "iopub.status.busy": "2023-11-30T13:22:55.857134Z",
     "iopub.status.idle": "2023-11-30T13:22:55.944052Z",
     "shell.execute_reply": "2023-11-30T13:22:55.943561Z",
     "shell.execute_reply.started": "2023-11-30T13:22:55.857408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/src/ngpt/__init__.py\n",
      "Has ngpt installed. Nothing to do.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 -c 'import ngpt; print(ngpt.__file__)' 2> '/dev/null'\n",
    "\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo \"Has ngpt installed. Nothing to do.\"\n",
    "else\n",
    "    echo \"Does not have ngpt installed. Installing...\"\n",
    "    git clone 'https://github.com/saforem2/nanoGPT'\n",
    "    python3 nanoGPT/data/shakespeare_char/prepare.py\n",
    "    python3 -m pip install -e nanoGPT -vvv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a8da7-72fe-4839-a14d-f01606285fc3",
   "metadata": {},
   "source": [
    "## Post Install\n",
    "\n",
    "If installed correctly, you should be able to:\n",
    "\n",
    "```python\n",
    ">>> import ngpt\n",
    ">>> ngpt.__file__\n",
    "'/path/to/nanoGPT/src/ngpt/__init__.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbf22d1-34ba-48ae-a78e-fc447fc9a0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:22:57.239396Z",
     "iopub.status.busy": "2023-11-30T13:22:57.239065Z",
     "iopub.status.idle": "2023-11-30T13:22:57.320991Z",
     "shell.execute_reply": "2023-11-30T13:22:57.320507Z",
     "shell.execute_reply.started": "2023-11-30T13:22:57.239380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:22:57]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m3434626787.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m7\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/src/ngpt/\u001b[0m\u001b[35m__init__.py\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ngpt\n",
    "from enrich import get_logger\n",
    "log = get_logger('jupyter')\n",
    "log.info(ngpt.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329ed94-582e-4aa8-bbe0-ba56782fe9e9",
   "metadata": {},
   "source": [
    "## Build Trainer\n",
    "\n",
    "Explicitly, we:\n",
    "\n",
    "1. `setup_torch(...)`\n",
    "2. Build `cfg: DictConfig = get_config(...)`\n",
    "3. Instnatiate `config: ExperimentConfig = instantiate(cfg)`\n",
    "4. Build `trainer = Trainer(config)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d12405a-8f88-476b-8922-a1a212adc682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:23:07.849887Z",
     "iopub.status.busy": "2023-11-30T13:23:07.849543Z",
     "iopub.status.idle": "2023-11-30T13:23:25.797076Z",
     "shell.execute_reply": "2023-11-30T13:23:25.796233Z",
     "shell.execute_reply.started": "2023-11-30T13:23:07.849870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   thetagpu23\n",
      "  Local device: mlx5_0\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:11]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m72\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Setting HF_DATASETS_CACHE to \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/.cache/huggingface/\u001b[0m\u001b[35mdatasets\u001b[0m\n",
      "Failed to download font: Source Sans Pro, skipping!\n",
      "Failed to download font: Titillium WebRoboto Condensed, skipping!\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m295\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Loading val from \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/data/openwebtext/\u001b[0m\u001b[35mval.bin\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m295\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Loading train from \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/data/openwebtext/\u001b[0m\u001b[35mtrain.bin\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[33m[WARNING]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m330\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - No meta.pkl found, assuming GPT-\u001b[35m2\u001b[0m encodings\u001b[33m...\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m270\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Rescaling GAS -> GAS \u001b[32m/\u001b[0m\u001b[32m/\u001b[0m WORLD_SIZE = \u001b[35m1\u001b[0m \u001b[32m/\u001b[0m\u001b[32m/\u001b[0m \u001b[35m1\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m432\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Tokens per iteration: \u001b[35m12\u001b[0m,\u001b[35m288\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m454\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Using \u001b[1m<\u001b[0m\u001b[1;95mtorch.amp.autocast_mode.autocast\u001b[0m\u001b[39m object at \u001b[0m\u001b[35m0x7f5f25dd6e90\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:15]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m187\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Initializing from OpenAI GPT-\u001b[35m2\u001b[0m Weights: gpt2\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:17]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m225\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - loading weights from pretrained gpt: gpt2\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:17]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m234\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - forcing \u001b[3;94mvocab_size\u001b[0m=\u001b[35m50257\u001b[0m, \u001b[3;94mblock_size\u001b[0m=\u001b[35m1024\u001b[0m, \u001b[3;94mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:17]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m240\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - overriding dropout rate to \u001b[35m0.0\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:19]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m160\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - number of parameters: \u001b[35m123.\u001b[0m65M\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:23]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m290\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - num decayed parameter tensors: \u001b[35m50\u001b[0m, with \u001b[35m124\u001b[0m,\u001b[35m318\u001b[0m,\u001b[35m464\u001b[0m parameters\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:23]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m291\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - num non-decayed parameter tensors: \u001b[35m98\u001b[0m, with \u001b[35m121\u001b[0m,\u001b[35m344\u001b[0m parameters\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:23]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m297\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - using fused AdamW: \u001b[3;92mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ezpz import setup_torch\n",
    "from hydra.utils import instantiate\n",
    "from ngpt.configs import get_config\n",
    "from ngpt.trainer import Trainer\n",
    "\n",
    "os.environ['MASTER_PORT'] = '4235'\n",
    "rank = setup_torch('DDP', seed=1234)\n",
    "cfg = get_config(\n",
    "    [\n",
    "        'data=owt',              # open web text\n",
    "        'model=gpt2',            # gpt2 arch.\n",
    "        'optimizer=gpt2',\n",
    "        'train=gpt2',\n",
    "        'train.init_from=gpt2',  # init from GPT2\n",
    "        'train.max_iters=1000',\n",
    "        'train.dtype=bfloat16',\n",
    "    ]\n",
    ")\n",
    "config = instantiate(cfg)\n",
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20e9355-fbcf-489e-afa1-f744486aec69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:23:25.799090Z",
     "iopub.status.busy": "2023-11-30T13:23:25.798634Z",
     "iopub.status.idle": "2023-11-30T13:23:33.868771Z",
     "shell.execute_reply": "2023-11-30T13:23:33.868178Z",
     "shell.execute_reply.started": "2023-11-30T13:23:25.799069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:33]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m3\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'prompt'\u001b[0m\u001b[1m]\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:23:33]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m4\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'response'\u001b[0m\u001b[1m]\u001b[0m:\n",
      "\n",
      "What is a supercomputer? When did you first learn it?\n",
      "\n",
      "I used to work in an Apple Computer. It was called the \u001b[32m\"Elgin\"\u001b[0m Computer. It was the first computer that I had seen on TV. I went to college in \u001b[35m1983\u001b[0m. I was at Arizona State University and I studied computer science. I later joined a computer science program at MIT. But my first computer was the Intel Core. It was from \u001b[35m1986\u001b[0m. I went to MIT where I got my PhD and was at the lab. When I did graduate school in \u001b[35m1987\u001b[0m, I went to Stanford where I made a few jobs.\n",
      "\n",
      "Did you ever think of programming as the \u001b[32m\"new media?\"\u001b[0m Did you ever think of learning about computers as the \u001b[32m\"new medium?\"\u001b[0m\n",
      "\n",
      "The world was changing. I started to think about the Internet as a new medium. I thought of computers as different from television and movies. My research led me to the Computer World. Where did you get that idea? It was a computer science book for people who were interested only in mathematics. I did research on the Internet. I went back to the Computer World which led me to programming.\n",
      "\n",
      "Do you remember talking to people that you know about how computers work?\n",
      "\n",
      "No, I don't think I did. I did not know what the concept of computers was actually like. For example, I hadn't taught programming to students in college. I was studying computer science. I never taught programming to any students. I was going to work on work on my computer.\n",
      "\n",
      "For those of you who were there, your own computers were what started the revolution. What were your first computers like?\n",
      "\n",
      "The first computer was a little bit like a calculator. It was very simple. You could use a calculator to count values. The following was just one number: \u001b[35m10\u001b[0m*\u001b[35m10\u001b[0m. You could use it to calculate your daily expenses and you could use it to write down what your income would be based on. It was all very simple.\n",
      "\n",
      "There's a very simple history of the Internet. Computers are not just about computers. They are a very important part of the world today. I am sure you have all your documents saved. We all have our personal computers. One computer, I remember, was a computer called Microsoft Word. Some of you remember it as Microsoft Word. I can't say anything about it. I'm not going to say much more. But I remember reading about the word Microsoft Word. It was all very\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a supercomputer?\"\n",
    "outputs = trainer.evaluate(query, num_samples=1, display=False)\n",
    "log.info(\"['prompt']: '{query}'\")\n",
    "log.info(\"['response']:\\n\\n\" + fr\"{outputs['0']['raw']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5202ff3-8811-47c9-8b9d-9818d4603697",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Legend:\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "\n",
    "|  **NAME**  |     **DESCRIPTION**          |\n",
    "|:----------:|:----------------------------:|\n",
    "|   `step`   | Current training step        |\n",
    "|   `loss`   | Loss value                   |\n",
    "|   `dt`     | Time per step (in **ms**)    |\n",
    "|   `sps`    | Samples per second           |\n",
    "|   `mtps`   | (million) Tokens per sec     |\n",
    "|   `mfu`    | Model Flops Utilization*     |\n",
    "\n",
    "*in units of A100 `bfloat16` peak FLOPS\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb8d33b-f8c9-41c6-aa61-95bdb76bf6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:23:34.115894Z",
     "iopub.status.busy": "2023-11-30T13:23:34.115543Z",
     "iopub.status.idle": "2023-11-30T13:28:26.957249Z",
     "shell.execute_reply": "2023-11-30T13:28:26.956700Z",
     "shell.execute_reply.started": "2023-11-30T13:23:34.115874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a080a3c40e418ea8c9db58fa2ba335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:24:29]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m100\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.119\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m267\u001b[0m\u001b[35m.101\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.744\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.046\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.610\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:24:56]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m200\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.961\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m228\u001b[0m\u001b[35m.076\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m4\u001b[0m\u001b[35m.385\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.054\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.825\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:25:22]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m300\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.022\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m276\u001b[0m\u001b[35m.843\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.612\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.044\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.759\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:25:48]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m400\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.002\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m234\u001b[0m\u001b[35m.589\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m4\u001b[0m\u001b[35m.263\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.052\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.919\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:26:14]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m500\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.004\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m291\u001b[0m\u001b[35m.194\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.434\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.042\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.784\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:26:41]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m600\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.071\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m267\u001b[0m\u001b[35m.192\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.743\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.046\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.766\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:27:08]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m700\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.118\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m247\u001b[0m\u001b[35m.305\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m4\u001b[0m\u001b[35m.044\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.050\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.851\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:27:34]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m800\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.218\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m279\u001b[0m\u001b[35m.384\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.579\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.044\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.772\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:28:00]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m900\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.736\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m282\u001b[0m\u001b[35m.449\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.540\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.044\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.687\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:28:26]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m1000\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.201\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m279\u001b[0m\u001b[35m.825\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.574\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.044\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m12\u001b[0m\u001b[35m.622\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.114\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.108\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_iters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c0c5a-539a-462d-a9e3-0655e8e48d85",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9350c9-6303-46bd-bcb5-70020b1d5564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:28:26.961332Z",
     "iopub.status.busy": "2023-11-30T13:28:26.961049Z",
     "iopub.status.idle": "2023-11-30T13:28:34.263010Z",
     "shell.execute_reply": "2023-11-30T13:28:34.262442Z",
     "shell.execute_reply.started": "2023-11-30T13:28:26.961313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:28:34]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m3\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'prompt'\u001b[0m\u001b[1m]\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:28:34]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m4\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'response'\u001b[0m\u001b[1m]\u001b[0m:\n",
      "\n",
      "What is a supercomputer? A supercomputer is a machine that is capable of using any available computing talent while being clever. It is the most beautiful piece of technology on the planet. In comparison to today's computers, the \u001b[32m'supercomputer'\u001b[0m is a small piece of technology that does not require any knowledge of maths, physics or mathematics of the material world.\n",
      "\n",
      "The computer is not just a computer that is smart - it is a computing device that has a deep understanding of the meaning and reality of the world around it - and it is an all-purpose machine, like a toy. When it is not \u001b[32m'computer'\u001b[0m it is a robot.\n",
      "\n",
      "This is a list of the wonderful machines on the planet.\n",
      "\n",
      "The \u001b[32m'computer'\u001b[0m itself is a very powerful machine. It is a very powerful computer at its best - it is capable of handling all sorts of things - many things, including playing video games, social media, movies and music. No doubt, the computer will be used for many other tasks.\n",
      "\n",
      "The computer is not just a computer that is smart - it is a machine that has a deep understanding of the meaning and reality of the world around it - and it is a very powerful machine, like a toy.\n",
      "\n",
      "Molecular computers are a different matter. They are devices that will help humans to understand how the world works.\n",
      "\n",
      "The \u001b[32m'supercomputer'\u001b[0m is a small piece of technology that is capable of using any available computing talent while being clever. It is the most beautiful piece of technology on the planet.\n",
      "\n",
      "The supercomputer is not just a computer that is smart - it is a computer that has a deep understanding of the meaning and reality of the world around it - and it is a very powerful machine, like a toy.\n",
      "\n",
      "The supercomputer is a very powerful machine - it is a computing device that has a deep understanding of the meaning and reality of the world around it - and it is a very powerful machine, like a toy.\n",
      "\n",
      "Virtual reality is a very powerful technology. This idea was popularised by Oculus, the company that created the Oculus Rift, which is the ultimate virtual reality company. Virtual Reality is not just a tech that is capable of being active and involved in the real world - it is a technology that is able to recreate real reality. It is a great idea, because it is a great idea is not limited to just a computer - it is able to be used for other tasks.\n",
      "\n",
      "Virtual reality is a\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a supercomputer?\"\n",
    "outputs = trainer.evaluate(query, num_samples=1, display=False)\n",
    "log.info(\"['prompt']: '{query}'\")\n",
    "log.info(\"['response']:\\n\\n\" + fr\"{outputs['0']['raw']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
