{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc5d004-5e6f-4bb3-938e-fb44f919cec3",
   "metadata": {},
   "source": [
    "# `nanoGPT`: GPT-2 Large (775M Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd994b32-ca5f-4e00-81d3-89dbbf7b2093",
   "metadata": {},
   "source": [
    "## Install / Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c38d27-5acb-4e5d-87c8-dbb2739cf277",
   "metadata": {},
   "source": [
    "### First Time Running\n",
    "\n",
    "We need to install `ngpt` and setup the Shakespeare dataset\n",
    "\n",
    "This will need to be ran the first time you are running this notebook.\n",
    "\n",
    "Following the\n",
    "\n",
    "```python\n",
    "!python3 -m pip install nanoGPT\n",
    "```\n",
    "\n",
    "you will need to restart your runtime (Runtime -> Restart runtime)\n",
    "\n",
    "After this, you should be able to\n",
    "\n",
    "```python\n",
    ">>> import ngpt\n",
    ">>> ngpt.__file__\n",
    "'/content/nanoGPT/src/ngpt/__init__.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910f8eab-53f3-48a3-8e7c-8d7c9ec5fc8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:43:40.904568Z",
     "iopub.status.busy": "2023-11-30T13:43:40.904396Z",
     "iopub.status.idle": "2023-11-30T13:43:41.006006Z",
     "shell.execute_reply": "2023-11-30T13:43:41.005514Z",
     "shell.execute_reply.started": "2023-11-30T13:43:40.904551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/src/ngpt/__init__.py\n",
      "Has ngpt installed. Nothing to do.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 -c 'import ngpt; print(ngpt.__file__)' 2> '/dev/null'\n",
    "\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo \"Has ngpt installed. Nothing to do.\"\n",
    "else\n",
    "    echo \"Does not have ngpt installed. Installing...\"\n",
    "    git clone 'https://github.com/saforem2/nanoGPT'\n",
    "    python3 nanoGPT/data/shakespeare_char/prepare.py\n",
    "    python3 -m pip install -e nanoGPT -vvv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a8da7-72fe-4839-a14d-f01606285fc3",
   "metadata": {},
   "source": [
    "## Post Install\n",
    "\n",
    "If installed correctly, you should be able to:\n",
    "\n",
    "```python\n",
    ">>> import ngpt\n",
    ">>> ngpt.__file__\n",
    "'/path/to/nanoGPT/src/ngpt/__init__.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbf22d1-34ba-48ae-a78e-fc447fc9a0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:43:57.977100Z",
     "iopub.status.busy": "2023-11-30T13:43:57.976678Z",
     "iopub.status.idle": "2023-11-30T13:43:58.059563Z",
     "shell.execute_reply": "2023-11-30T13:43:58.059053Z",
     "shell.execute_reply.started": "2023-11-30T13:43:57.977081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:43:58]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m3434626787.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m7\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/src/ngpt/\u001b[0m\u001b[35m__init__.py\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ngpt\n",
    "from enrich import get_logger\n",
    "log = get_logger('jupyter')\n",
    "log.info(ngpt.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329ed94-582e-4aa8-bbe0-ba56782fe9e9",
   "metadata": {},
   "source": [
    "## Build Trainer\n",
    "\n",
    "Explicitly, we:\n",
    "\n",
    "1. `setup_torch(...)`\n",
    "2. Build `cfg: DictConfig = get_config(...)`\n",
    "3. Instnatiate `config: ExperimentConfig = instantiate(cfg)`\n",
    "4. Build `trainer = Trainer(config)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d12405a-8f88-476b-8922-a1a212adc682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:43:58.291866Z",
     "iopub.status.busy": "2023-11-30T13:43:58.291513Z",
     "iopub.status.idle": "2023-11-30T13:44:32.925793Z",
     "shell.execute_reply": "2023-11-30T13:44:32.924731Z",
     "shell.execute_reply.started": "2023-11-30T13:43:58.291848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   thetagpu23\n",
      "  Local device: mlx5_0\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:02]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m72\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Setting HF_DATASETS_CACHE to \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/.cache/huggingface/\u001b[0m\u001b[35mdatasets\u001b[0m\n",
      "Failed to download font: Source Sans Pro, skipping!\n",
      "Failed to download font: Titillium WebRoboto Condensed, skipping!\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m295\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Loading val from \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/data/openwebtext/\u001b[0m\u001b[35mval.bin\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m295\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Loading train from \u001b[32m/lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/nanoGPT/data/openwebtext/\u001b[0m\u001b[35mtrain.bin\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[33m[WARNING]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m330\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - No meta.pkl found, assuming GPT-\u001b[35m2\u001b[0m encodings\u001b[33m...\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m270\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Rescaling GAS -> GAS \u001b[32m/\u001b[0m\u001b[32m/\u001b[0m WORLD_SIZE = \u001b[35m1\u001b[0m \u001b[32m/\u001b[0m\u001b[32m/\u001b[0m \u001b[35m1\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m432\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Tokens per iteration: \u001b[35m512\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mconfigs.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m454\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Using \u001b[1m<\u001b[0m\u001b[1;95mtorch.amp.autocast_mode.autocast\u001b[0m\u001b[39m object at \u001b[0m\u001b[35m0x7f6ea7470a90\u001b[0m\u001b[1m>\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m187\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - Initializing from OpenAI GPT-\u001b[35m2\u001b[0m Weights: gpt2-large\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:07]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m225\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - loading weights from pretrained gpt: gpt2-large\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:07]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m234\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - forcing \u001b[3;94mvocab_size\u001b[0m=\u001b[35m50257\u001b[0m, \u001b[3;94mblock_size\u001b[0m=\u001b[35m1024\u001b[0m, \u001b[3;94mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:07]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m240\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - overriding dropout rate to \u001b[35m0.0\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:19]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m160\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - number of parameters: \u001b[35m772.\u001b[0m72M\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m290\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - num decayed parameter tensors: \u001b[35m146\u001b[0m, with \u001b[35m773\u001b[0m,\u001b[35m428\u001b[0m,\u001b[35m480\u001b[0m parameters\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m291\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - num non-decayed parameter tensors: \u001b[35m290\u001b[0m, with \u001b[35m601\u001b[0m,\u001b[35m600\u001b[0m parameters\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mmodel.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m297\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - using fused AdamW: \u001b[3;92mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ezpz import setup_torch\n",
    "from hydra.utils import instantiate\n",
    "from ngpt.configs import get_config, PROJECT_ROOT\n",
    "from ngpt.trainer import Trainer\n",
    "\n",
    "HF_DATASETS_CACHE = PROJECT_ROOT.joinpath('.cache', 'huggingface')\n",
    "HF_DATASETS_CACHE.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "os.environ['MASTER_PORT'] = '5631'\n",
    "os.environ['HF_DATASETS_CACHE'] = HF_DATASETS_CACHE.as_posix()\n",
    "\n",
    "rank = setup_torch('DDP', seed=1234)\n",
    "cfg = get_config(\n",
    "    [\n",
    "        'data=owt',\n",
    "        'model=gpt2_large',\n",
    "        'model.block_size=128',\n",
    "        'optimizer=gpt2_large',\n",
    "        'train=gpt2_large',\n",
    "        'train.init_from=gpt2-large',\n",
    "        'train.max_iters=1000',\n",
    "        'train.dtype=bfloat16',\n",
    "    ]\n",
    ")\n",
    "config = instantiate(cfg)\n",
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61b91d-52da-4c42-8d59-3d56e0745e02",
   "metadata": {},
   "source": [
    "## Prompt (prior to training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a97262-93b8-4ac1-920a-dad3b8ef74e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:44:32.928658Z",
     "iopub.status.busy": "2023-11-30T13:44:32.928048Z",
     "iopub.status.idle": "2023-11-30T13:44:53.766313Z",
     "shell.execute_reply": "2023-11-30T13:44:53.765641Z",
     "shell.execute_reply.started": "2023-11-30T13:44:32.928640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:53]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m3\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'prompt'\u001b[0m\u001b[1m]\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:44:53]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m4\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'response'\u001b[0m\u001b[1m]\u001b[0m:\n",
      "\n",
      "What is a supercomputer? A supercomputer is a computer that can run more than one hundred thousand instructions per second. It's basically like a computer that can simulate a human brain. So, if we had a supercomputer with a billion instructions per second, that's forty-seven times as fast as the brain itself.\n",
      "\n",
      "A supercomputer is something that we can invent and code and build. But we're not going to have one, because we're not going to have a supercomputer. There are some things that we can do with computers, that computers can't accomplish.\n",
      "\n",
      "So, let's think about, for instance, programming language. We have ten thousand programming languages. So, what is a programming language? A programming language is a language that lets you write a program. And if you say, \u001b[32m\"OK, if I want to do this, I'm going to write a program to do this,\"\u001b[0m you have a programming language. If I want to do that, I'm going to write a program to do that.\n",
      "\n",
      "What is a programming language? If I want to write a program which will give the instructions to turn on a lightbulb, I am going to write a program to write a program that turns on a lightbulb. And that program is programming language.\n",
      "\n",
      "You have the one hundred thousand programming languages. You have a programming language that lets you write a program. The next step is to create a programming language that allows you to program. And since we live in a computer world, you can't create a programming language that will give you all the instructions to change the color of your hand.\n",
      "\n",
      "So, we're stuck with languages that let you write programs. And some people would say that's a good thing. But there are some things that you can't do. I was never finished with my writing until I had this idea and I thought, \u001b[32m\"I am going to write some programs that will let me turn on and off lights in the house,\"\u001b[0m or, \u001b[32m\"I am going to say, 'turn on or off the light,'\"\u001b[0m and I think, \u001b[32m\"What if I turn on a lightbulb?\"\u001b[0m\n",
      "\n",
      "And so, I started a programming language called AVR. It's a very simple language. No real logic. It doesn't allow me to say, \u001b[32m\"I won't turn on the light if I don't want to.\"\u001b[0m And so when I wrote it, I thought, \"OK, this is my first programming\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a supercomputer?\"\n",
    "outputs = trainer.evaluate(query, num_samples=1, display=False)\n",
    "log.info(\"['prompt']: '{query}'\")\n",
    "log.info(\"['response']:\\n\\n\" + fr\"{outputs['0']['raw']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de5cdd-6713-4d61-88bd-6fcd47270edd",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb8d33b-f8c9-41c6-aa61-95bdb76bf6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:44:53.767661Z",
     "iopub.status.busy": "2023-11-30T13:44:53.767240Z",
     "iopub.status.idle": "2023-11-30T13:55:11.795343Z",
     "shell.execute_reply": "2023-11-30T13:55:11.794728Z",
     "shell.execute_reply.started": "2023-11-30T13:44:53.767642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f983115938e14501893880482ef2a8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 07:46:25]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m100\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.422\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m563\u001b[0m\u001b[35m.654\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.774\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m36\u001b[0m\u001b[35m.352\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:47:23]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m200\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.877\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m575\u001b[0m\u001b[35m.121\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.739\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m36\u001b[0m\u001b[35m.280\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:48:22]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m300\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.465\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m586\u001b[0m\u001b[35m.089\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.706\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m36\u001b[0m\u001b[35m.148\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:49:20]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m400\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.615\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m580\u001b[0m\u001b[35m.777\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.722\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m36\u001b[0m\u001b[35m.061\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:50:19]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m500\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.006\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m589\u001b[0m\u001b[35m.075\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.698\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m35\u001b[0m\u001b[35m.933\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:51:17]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m600\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.524\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m585\u001b[0m\u001b[35m.214\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.709\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m35\u001b[0m\u001b[35m.841\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:52:16]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m700\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.904\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m600\u001b[0m\u001b[35m.498\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.665\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m35\u001b[0m\u001b[35m.669\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:53:14]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m800\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.792\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m587\u001b[0m\u001b[35m.085\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.703\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m35\u001b[0m\u001b[35m.592\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:54:13]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m900\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.790\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m588\u001b[0m\u001b[35m.443\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.699\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m35\u001b[0m\u001b[35m.515\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 07:55:11]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119mtrainer.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m518\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[3;94mstep\u001b[0m=\u001b[35m1000\u001b[0m \u001b[3;94mloss\u001b[0m=\u001b[35m3\u001b[0m\u001b[35m.065\u001b[0m \u001b[3;94mdt\u001b[0m=\u001b[35m616\u001b[0m\u001b[35m.307\u001b[0m \u001b[3;94msps\u001b[0m=\u001b[35m1\u001b[0m\u001b[35m.623\u001b[0m \u001b[3;94mmtps\u001b[0m=\u001b[35m0\u001b[0m\u001b[35m.001\u001b[0m \u001b[3;94mmfu\u001b[0m=\u001b[35m35\u001b[0m\u001b[35m.288\u001b[0m \u001b[3;94mtrain_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.662\u001b[0m \u001b[3;94mval_loss\u001b[0m=\u001b[35m2\u001b[0m\u001b[35m.654\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c0c5a-539a-462d-a9e3-0655e8e48d85",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdde05ef-60c9-4847-b773-74aa5411f058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:59:45.063709Z",
     "iopub.status.busy": "2023-11-30T13:59:45.063222Z",
     "iopub.status.idle": "2023-11-30T14:00:05.169348Z",
     "shell.execute_reply": "2023-11-30T14:00:05.168762Z",
     "shell.execute_reply.started": "2023-11-30T13:59:45.063687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;131;131;131m[2023-11-30 08:00:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m3\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'prompt'\u001b[0m\u001b[1m]\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mquery\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
      "\u001b[38;2;131;131;131m[2023-11-30 08:00:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[38;2;119;119;119m[\u001b[0m\u001b[38;2;119;119;119m1657463709.py\u001b[0m\u001b[38;2;119;119;119m:\u001b[0m\u001b[38;2;119;119;119m4\u001b[0m\u001b[38;2;119;119;119m]\u001b[0m - \u001b[1m[\u001b[0m\u001b[32m'response'\u001b[0m\u001b[1m]\u001b[0m:\n",
      "\n",
      "What is a supercomputer? There is no place on Earth where they can make “a supercomputer.” It’s called Deep Space Computer, or DSC, and only the U.S. military has it.\n",
      "\n",
      "What kind of computer can you build? DSC lets us take an image, an equation, a concept, and manipulate it in ways that are orders of magnitude more powerful than any human, and could one day outpace us. We use the computer to make scientific breakthroughs, and to make our everyday lives more complex and interesting.\n",
      "\n",
      "What will the computer do? The computer’s job is to do mathematics, which means it can do a fraction of the number of calculations in a human lifetime. This does not mean that the computer has any physical characteristics. The computer’s computer is an intellectual tool, a computer that can understand the world, and it can learn how to solve problems. If you want to build a computer, you must find the way that it does this.\n",
      "\n",
      "What’s the difference between a small computer, a big computer? Small computers are very simple ones that use a single, very small, very powerful computer to solve a problem or another. They can solve a problem, or turn a problem into an algorithm. For the big computers, you need to use a supercomputer to do the big stuff. Scientists build massive computers that are built from massive, millions of computer chips. Supercomputers have to be built into the hardware, where they run their entire life cycle after cycle. This is a very different kind of computer. They are really big, big computers.\n",
      "\n",
      "What is a machine? A machine is the computer that is extremely intelligent. They can explain itself. They can solve problems. They can solve problems that are so complicated, they come up with ways to do it. They can make incredible discoveries. They can solve problems that you would never have thought possible. These machines are machines because they are not machines. They are the kind of machines we imagine in our own heads.\n",
      "\n",
      "How is the life of the machine? The whole point of computers is to make machines. The very act of writing an instruction manual, the way machines were built, means that the machine is a machine. They’re machines. They make machines, and get the machine out of its machine.\n",
      "\n",
      "How does computers help us make machines? We build machines out of our brain, our computer,\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a supercomputer?\"\n",
    "outputs = trainer.evaluate(query, num_samples=1, display=False)\n",
    "log.info(\"['prompt']: '{query}'\")\n",
    "log.info(\"['response']:\\n\\n\" + fr\"{outputs['0']['raw']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
